"""
AIåˆ†æAPIè·¯ç”±
"""
from fastapi import APIRouter, UploadFile, File, HTTPException, Query, Form
from typing import Optional, List
from datetime import datetime
import json
from app.models.schemas import AnalysisResponse
from app.services.ai_analysis_service import ai_analysis_service

router = APIRouter(prefix="/api/analysis", tags=["analysis"])


@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_image(
    file: UploadFile = File(...),
    patient_id: str = Query(..., description="æ‚£è€…ID"),
    camera_id: Optional[str] = Query(None, description="æ‘„åƒå¤´ID"),
    timestamp_ms: Optional[int] = Query(None, description="æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰")
):
    """ä¸Šä¼ å›¾ç‰‡è¿›è¡ŒAIåˆ†æ"""
    import logging
    import traceback
    from datetime import datetime
    
    logger = logging.getLogger(__name__)
    start_time = datetime.now()
    
    try:
        logger.info(f"ğŸ“¥ [API] æ”¶åˆ°å›¾ç‰‡åˆ†æè¯·æ±‚")
        logger.info(f"ğŸ“¥ [API] æ‚£è€…ID: {patient_id}")
        logger.info(f"ğŸ“¥ [API] æ‘„åƒå¤´ID: {camera_id}")
        logger.info(f"ğŸ“¥ [API] æ—¶é—´æˆ³: {timestamp_ms}ms")
        logger.info(f"ğŸ“¥ [API] æ–‡ä»¶å: {file.filename}, ç±»å‹: {file.content_type}, å¤§å°: {file.size if hasattr(file, 'size') else 'æœªçŸ¥'}")
        
        # è¯»å–å›¾ç‰‡æ•°æ®
        logger.info(f"ğŸ“¥ [API] è¯»å–å›¾ç‰‡æ•°æ®...")
        image_bytes = await file.read()
        
        if len(image_bytes) == 0:
            logger.error(f"âŒ [API] å›¾ç‰‡æ–‡ä»¶ä¸ºç©º")
            raise HTTPException(status_code=400, detail="å›¾ç‰‡æ–‡ä»¶ä¸ºç©º")
        
        logger.info(f"ğŸ“¥ [API] å›¾ç‰‡æ•°æ®è¯»å–å®Œæˆ: {len(image_bytes)} bytes")
        
        # è°ƒç”¨AIåˆ†ææœåŠ¡
        logger.info(f"ğŸ“¥ [API] è°ƒç”¨AIåˆ†ææœåŠ¡...")
        result = await ai_analysis_service.analyze_patient_image(
            image_bytes=image_bytes,
            patient_id=patient_id,
            camera_id=camera_id,
            timestamp_ms=timestamp_ms
        )
        
        total_duration = (datetime.now() - start_time).total_seconds()
        logger.info(f"âœ… [API] åˆ†æå®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        return AnalysisResponse(**result)
        
    except HTTPException as e:
        total_duration = (datetime.now() - start_time).total_seconds()
        logger.error(f"âŒ [API] HTTPå¼‚å¸¸ (è€—æ—¶: {total_duration:.2f}ç§’): {e.status_code} - {e.detail}")
        raise
    except Exception as e:
        total_duration = (datetime.now() - start_time).total_seconds()
        error_trace = traceback.format_exc()
        logger.error(f"âŒ [API] åˆ†æå¤±è´¥ (è€—æ—¶: {total_duration:.2f}ç§’)")
        logger.error(f"âŒ [API] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        logger.error(f"âŒ [API] å¼‚å¸¸æ¶ˆæ¯: {str(e)}")
        logger.error(f"âŒ [API] å®Œæ•´å †æ ˆè·Ÿè¸ª:\n{error_trace}")
        raise HTTPException(
            status_code=500, 
            detail=f"åˆ†æå¤±è´¥: {str(e)}\n\né”™è¯¯ç±»å‹: {type(e).__name__}\n\nå †æ ˆè·Ÿè¸ª:\n{error_trace}"
        )


@router.post("/batch", response_model=List[dict])
async def analyze_batch(
    files: List[UploadFile] = File(...),
    frames: str = Form(..., description="å¸§å…ƒæ•°æ®JSONå­—ç¬¦ä¸²")
):
    """æ‰¹é‡ä¸Šä¼ å›¾ç‰‡è¿›è¡ŒAIåˆ†æ"""
    try:
        # è§£æå¸§å…ƒæ•°æ®
        try:
            frames_data = json.loads(frames)
        except json.JSONDecodeError:
            raise HTTPException(status_code=400, detail="å¸§å…ƒæ•°æ®æ ¼å¼é”™è¯¯")
        
        if len(files) != len(frames_data):
            raise HTTPException(status_code=400, detail="æ–‡ä»¶æ•°é‡ä¸å…ƒæ•°æ®æ•°é‡ä¸åŒ¹é…")
        
        # æ‰¹é‡å¤„ç†
        results = []
        for i, file in enumerate(files):
            try:
                image_bytes = await file.read()
                if len(image_bytes) == 0:
                    results.append({
                        "status": "failed",
                        "error": "å›¾ç‰‡æ–‡ä»¶ä¸ºç©º",
                        "index": i
                    })
                    continue
                
                frame_info = frames_data[i]
                result = await ai_analysis_service.analyze_patient_image(
                    image_bytes=image_bytes,
                    patient_id=frame_info.get("patient_id"),
                    camera_id=frame_info.get("camera_id"),
                    timestamp_ms=frame_info.get("timestamp_ms")
                )
                
                results.append({
                    "status": "success",
                    "index": i,
                    "result": result
                })
            except Exception as e:
                results.append({
                    "status": "failed",
                    "error": str(e),
                    "index": i
                })
        
        return results
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")


@router.get("/history/{patient_id}", response_model=list)
async def get_analysis_history(
    patient_id: str,
    start_date: Optional[str] = Query(None),
    end_date: Optional[str] = Query(None),
    limit: int = Query(100, le=1000)
):
    """è·å–åˆ†æå†å²"""
    try:
        start = datetime.fromisoformat(start_date) if start_date else None
        end = datetime.fromisoformat(end_date) if end_date else None
        
        results = await ai_analysis_service.get_analysis_history(
            patient_id=patient_id,
            start_date=start,
            end_date=end,
            limit=limit
        )
        
        return results
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/upload-image", response_model=AnalysisResponse)
async def upload_image(
    file: UploadFile = File(...),
    patient_id: str = Query(..., description="æ‚£è€…ID"),
    camera_id: Optional[str] = Query(None, description="æ‘„åƒå¤´ID"),
    timestamp_ms: Optional[int] = Query(None, description="æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰")
):
    """ä¸Šä¼ å›¾ç‰‡å¹¶è¿›è¡Œåˆ†æï¼ˆæ‚£è€…ç«¯æ‘„åƒå¤´æ‹æ‘„ï¼‰"""
    # å¤ç”¨analyzeæ¥å£çš„é€»è¾‘
    return await analyze_image(file, patient_id, camera_id, timestamp_ms)


@router.post("/upload-video", response_model=AnalysisResponse)
async def upload_video(
    file: UploadFile = File(...),
    patient_id: str = Query(..., description="æ‚£è€…ID"),
    camera_id: Optional[str] = Query(None, description="æ‘„åƒå¤´ID"),
    timestamp_ms: Optional[int] = Query(None, description="æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰")
):
    """ä¸Šä¼ è§†é¢‘å¹¶è¿›è¡Œåˆ†æï¼ˆæ‚£è€…ç«¯å½•åˆ¶ï¼‰"""
    import logging
    import traceback
    from datetime import datetime
    
    logger = logging.getLogger(__name__)
    start_time = datetime.now()
    
    try:
        logger.info(f"ğŸ“¥ [API] æ”¶åˆ°è§†é¢‘ä¸Šä¼ è¯·æ±‚")
        logger.info(f"ğŸ“¥ [API] æ‚£è€…ID: {patient_id}")
        logger.info(f"ğŸ“¥ [API] æ–‡ä»¶å: {file.filename}, ç±»å‹: {file.content_type}")
        
        # è¯»å–è§†é¢‘æ•°æ®
        video_bytes = await file.read()
        
        if len(video_bytes) == 0:
            raise HTTPException(status_code=400, detail="è§†é¢‘æ–‡ä»¶ä¸ºç©º")
        
        logger.info(f"ğŸ“¥ [API] è§†é¢‘æ•°æ®è¯»å–å®Œæˆ: {len(video_bytes)} bytes")
        
        # å¯¹äºè§†é¢‘ï¼Œå¯ä»¥æå–å…³é”®å¸§è¿›è¡Œåˆ†æ
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥è¿”å›æˆåŠŸï¼ˆå®é™…åº”è¯¥æå–å¸§å¹¶åˆ†æï¼‰
        # TODO: å®ç°è§†é¢‘å¸§æå–å’ŒAIåˆ†æ
        
        return AnalysisResponse(
            status="success",
            result_id=None,
            analysis={"message": "è§†é¢‘å·²æ¥æ”¶ï¼Œå¾…å¤„ç†"},
            error=None
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_trace = traceback.format_exc()
        logger.error(f"âŒ [API] è§†é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è§†é¢‘ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.get("/timeline/{patient_id}", response_model=list)
async def get_timeline(
    patient_id: str,
    start_date: Optional[str] = Query(None),
    end_date: Optional[str] = Query(None),
    limit: int = Query(100, le=1000)
):
    """è·å–æ—¶é—´è½´æ•°æ®ï¼ˆæŒ‰æ—¶é—´æŸ¥è¯¢åˆ†æç»“æœï¼‰"""
    try:
        start = datetime.fromisoformat(start_date) if start_date else None
        end = datetime.fromisoformat(end_date) if end_date else None
        
        results = await ai_analysis_service.get_analysis_history(
            patient_id=patient_id,
            start_date=start,
            end_date=end,
            limit=limit
        )
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        timeline = []
        for result in results:
            try:
                import json
                analysis_data = json.loads(result['analysis_data']) if isinstance(result['analysis_data'], str) else result['analysis_data']
                timeline.append({
                    "result_id": result['result_id'],
                    "timestamp": result['timestamp'],
                    "detection_type": result['detection_type'],
                    "analysis_data": analysis_data,
                    "snapshot_url": result.get('snapshot_url'),
                    "is_alert_triggered": result.get('is_alert_triggered', 0) == 1,
                })
            except:
                continue
        
        return timeline
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/summary/{patient_id}", response_model=dict)
async def get_analysis_summary(
    patient_id: str,
    start_date: Optional[str] = Query(None),
    end_date: Optional[str] = Query(None)
):
    """è·å–æ—¶é—´æ®µæ±‡æ€»åˆ†æ"""
    from datetime import datetime, timedelta
    
    try:
        start = datetime.fromisoformat(start_date) if start_date else datetime.now() - timedelta(days=1)
        end = datetime.fromisoformat(end_date) if end_date else datetime.now()
        
        results = await ai_analysis_service.get_analysis_history(
            patient_id=patient_id,
            start_date=start,
            end_date=end,
            limit=1000
        )
        
        # ç»Ÿè®¡æ±‡æ€»
        total_count = len(results)
        alert_count = sum(1 for r in results if r.get('is_alert_triggered', 0) == 1)
        
        # æŒ‰æ£€æµ‹ç±»å‹ç»Ÿè®¡
        detection_types = {}
        for result in results:
            dt = result.get('detection_type', 'unknown')
            detection_types[dt] = detection_types.get(dt, 0) + 1
        
        # åˆ†æå¼‚å¸¸æƒ…å†µ
        anomalies = []
        for result in results:
            if result.get('is_alert_triggered', 0) == 1:
                try:
                    import json
                    analysis_data = json.loads(result['analysis_data']) if isinstance(result['analysis_data'], str) else result['analysis_data']
                    detections = analysis_data.get('detections', {})
                    
                    # æå–å¼‚å¸¸ä¿¡æ¯
                    for key, value in detections.items():
                        if isinstance(value, dict) and value.get('detected'):
                            anomalies.append({
                                "timestamp": result['timestamp'],
                                "type": key,
                                "description": value.get('description', ''),
                            })
                except:
                    continue
        
        return {
            "patient_id": patient_id,
            "start_date": start.isoformat(),
            "end_date": end.isoformat(),
            "total_count": total_count,
            "alert_count": alert_count,
            "detection_types": detection_types,
            "anomalies": anomalies[:20],  # æœ€å¤šè¿”å›20æ¡å¼‚å¸¸
        }
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

