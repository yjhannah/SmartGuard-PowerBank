# æƒ…ç»ªè¯†åˆ«æ•°æ®ä¿å­˜ä¸æ—¶é—´çº¿å›æ”¾æ–¹æ¡ˆ

**ç‰ˆæœ¬**: v1.0  
 
**ç›®æ ‡**: å®ç°æƒ…ç»ªè¯†åˆ«æ•°æ®æŒä¹…åŒ–å­˜å‚¨ï¼Œæ”¯æŒæŠ¥å‘Šé¡µé¢å±•ç¤ºå’Œè§†é¢‘æ—¶é—´çº¿å›æ”¾

---

## 1. éœ€æ±‚åˆ†æ

### 1.1 å½“å‰ç³»ç»ŸçŠ¶æ€

#### å‰ç«¯æƒ…ç»ªé‡‡é›† (`interview_live_page.dart`)

```dart
// å½“å‰å®ç°ï¼šç¬¬ 349-375 è¡Œ
Future<void> _captureAndAnalyze() async {
  final resp = await ApiService.analyzeVision(bytes, _interviewId!);
  setState(() {
    currentEmotion = resp['emotion'] ?? 'Unknown';
    stressLevel = (resp['stress_level'] ?? 0).toDouble();
    confidence = resp['confidence'] ?? 'medium';
    notes = resp['notes'] ?? '';
    _lastVisionAt = DateTime.now();
    // âŒ é—®é¢˜ï¼šæ•°æ®åªä¿å­˜åœ¨å†…å­˜å˜é‡ä¸­ï¼Œæ²¡æœ‰ç´¯ç§¯åˆ°åˆ—è¡¨
    // âŒ é—®é¢˜ï¼šåœæ­¢å½•åˆ¶æ—¶ï¼Œæƒ…ç»ªæ•°æ®æ²¡æœ‰ä¸Šä¼ åˆ°æ•°æ®åº“
  });
}
```

**é—®é¢˜æ¸…å•**ï¼š
| é—®é¢˜ | å½±å“ |
|------|------|
| æƒ…ç»ªæ•°æ®åªå­˜åœ¨å†…å­˜ä¸­ | é¡µé¢åˆ·æ–°åæ•°æ®ä¸¢å¤± |
| æ²¡æœ‰æ—¶é—´æˆ³è®°å½• | æ— æ³•ä¸è§†é¢‘æ—¶é—´çº¿å…³è” |
| åœæ­¢å½•åˆ¶æ—¶æœªä¸Šä¼  | æŠ¥å‘Šé¡µé¢æ— æ•°æ®å±•ç¤º |

#### åç«¯æƒ…ç»ªåˆ†æ (`analysis.py`)

```python
# å½“å‰å®ç°ï¼šç¬¬ 52-105 è¡Œ
@router.post("/vision", response_model=VisionAnalysisResponse)
async def analyze_vision(file: UploadFile, interview_id: str):
    # âœ… è°ƒç”¨ Gemini åˆ†æå›¾ç‰‡
    analysis = client.analyze_image(content, file.content_type)
    return analysis
    # âŒ é—®é¢˜ï¼šæ²¡æœ‰å°†ç»“æœä¿å­˜åˆ° aura_interview_events è¡¨
```

#### æŠ¥å‘Šé¡µé¢ (`interview_report_page.dart`)

```dart
// å½“å‰å®ç°ï¼šç¬¬ 380-452 è¡Œ
Widget _buildEmotionTimeline() {
  final emotionEvents = _events.where((e) => 
    e['event_type'] == 'emotion_analysis'  // æŸ¥è¯¢æƒ…ç»ªäº‹ä»¶
  ).toList();
  
  if (emotionEvents.isEmpty)
    return Text('æš‚æ— æƒ…ç»ªæ•°æ®');  // âŒ å½“å‰æ€»æ˜¯æ˜¾ç¤ºè¿™ä¸ª
  // ...
}
```

### 1.2 ç›®æ ‡åŠŸèƒ½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        é¢è¯•å½•åˆ¶é˜¶æ®µ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   [æ‘„åƒå¤´] â”€â”€> [æ™ºèƒ½é‡‡æ ·] â”€â”€> [æƒ…ç»ªåˆ†æ API]                     â”‚
â”‚                    â”‚                â”‚                           â”‚
â”‚                    â–¼                â–¼                           â”‚
â”‚         [æœ¬åœ° EmotionRecords]   [è¿”å›åˆ†æç»“æœ]                   â”‚
â”‚         (å¸¦æ—¶é—´æˆ³ç´¯ç§¯)                                          â”‚
â”‚                    â”‚                                            â”‚
â”‚                    â”‚ ç‚¹å‡»åœæ­¢å½•åˆ¶                               â”‚
â”‚                    â–¼                                            â”‚
â”‚           [æ‰¹é‡ä¸Šä¼ æƒ…ç»ªæ•°æ®]                                    â”‚
â”‚                    â”‚                                            â”‚
â”‚                    â–¼                                            â”‚
â”‚         [aura_interview_events è¡¨]                              â”‚
â”‚         (event_type = 'emotion_analysis')                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æŸ¥çœ‹æŠ¥å‘Šé˜¶æ®µ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   [æŠ¥å‘Šé¡µé¢] â”€â”€> [GET /interview/{id}/events]                   â”‚
â”‚                    â”‚                                            â”‚
â”‚                    â–¼                                            â”‚
â”‚         [æƒ…ç»ªæ—¶é—´çº¿ç»„ä»¶]    [è§†é¢‘æ’­æ”¾å™¨]                         â”‚
â”‚                â”‚                  â”‚                             â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                         â”‚ ç‚¹å‡»æ—¶é—´çº¿èŠ‚ç‚¹                        â”‚
â”‚                         â–¼                                       â”‚
â”‚              [è§†é¢‘è·³è½¬åˆ°å¯¹åº”æ—¶é—´ç‚¹]                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. æŠ€æœ¯æ–¹æ¡ˆ

### 2.1 æ•´ä½“æ¶æ„ï¼ˆæ•´åˆæˆæœ¬ä¼˜åŒ–ï¼‰

ç»“åˆ [è§†é¢‘åˆ†ææˆæœ¬ä¼˜åŒ–ç®—æ³•æ–¹æ¡ˆ](./20251121hw_è§†é¢‘åˆ†ææˆæœ¬ä¼˜åŒ–ç®—æ³•æ–¹æ¡ˆ.md) çš„å››å±‚æ¼æ–—ç­–ç•¥ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: æ™ºèƒ½å˜åŒ–æ£€æµ‹ (å‰ç«¯)        â”‚  æ¯ç§’é‡‡æ · â†’ åªä¸Šä¼ å˜åŒ–å¸§
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 2: è¯­ä¹‰å…³é”®ç‚¹è§¦å‘ (å¯é€‰)      â”‚  é¢è¯•å®˜æé—®åå¿…é‡‡æ ·
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 3: æœ¬åœ°ç´¯ç§¯ + æ‰¹é‡ä¸Šä¼         â”‚  ç´¯ç§¯æ•°æ®ï¼Œåœæ­¢æ—¶æ‰¹é‡ä¿å­˜
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 4: æ•°æ®åº“æŒä¹…åŒ–              â”‚  emotion_analysis äº‹ä»¶
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å‰ç«¯æ•°æ®ç»“æ„

#### 2.2.1 EmotionRecord æ¨¡å‹

```dart
// æ–°å¢æ–‡ä»¶: frontend/lib/models/emotion_record.dart

class EmotionRecord {
  final int timestampMs;      // è·ç¦»å½•åˆ¶å¼€å§‹çš„æ¯«ç§’æ•°
  final String emotion;       // æƒ…ç»ªç±»å‹: happy, sad, angry, surprised, neutral
  final double stressLevel;   // å‹åŠ›ç­‰çº§: 0-10
  final String confidence;    // ç½®ä¿¡åº¦: low, medium, high
  final String notes;         // AI åˆ†æå¤‡æ³¨
  final DateTime createdAt;   // åˆ›å»ºæ—¶é—´
  
  EmotionRecord({
    required this.timestampMs,
    required this.emotion,
    required this.stressLevel,
    required this.confidence,
    required this.notes,
    DateTime? createdAt,
  }) : createdAt = createdAt ?? DateTime.now();
  
  Map<String, dynamic> toJson() => {
    'timestamp_ms': timestampMs,
    'emotion': emotion,
    'stress_level': stressLevel,
    'confidence': confidence,
    'notes': notes,
    'created_at': createdAt.toIso8601String(),
  };
  
  factory EmotionRecord.fromJson(Map<String, dynamic> json) => EmotionRecord(
    timestampMs: json['timestamp_ms'] ?? 0,
    emotion: json['emotion'] ?? 'unknown',
    stressLevel: (json['stress_level'] ?? 0).toDouble(),
    confidence: json['confidence'] ?? 'medium',
    notes: json['notes'] ?? '',
    createdAt: json['created_at'] != null 
        ? DateTime.parse(json['created_at']) 
        : null,
  );
}
```

#### 2.2.2 æ™ºèƒ½é‡‡æ ·æ§åˆ¶å™¨

```dart
// æ–°å¢æ–‡ä»¶: frontend/lib/services/emotion_sampling_service.dart

import 'dart:typed_data';
import 'dart:html' as html;

class EmotionSamplingService {
  Uint8List? _lastFrameData;
  final double changeThreshold;  // å˜åŒ–é˜ˆå€¼ (é»˜è®¤ 0.15 = 15%)
  
  EmotionSamplingService({this.changeThreshold = 0.15});
  
  /// åˆ¤æ–­å½“å‰å¸§æ˜¯å¦åº”è¯¥ä¸Šä¼ åˆ†æ
  /// åŸºäº Layer 1: å¸§å·®æ³•æ£€æµ‹
  bool shouldAnalyze(html.CanvasElement canvas) {
    final ctx = canvas.context2D;
    final imageData = ctx.getImageData(0, 0, canvas.width!, canvas.height!);
    final currentData = Uint8List.fromList(imageData.data);
    
    // é¦–å¸§å¿…é¡»åˆ†æ
    if (_lastFrameData == null) {
      _lastFrameData = currentData;
      return true;
    }
    
    // è®¡ç®—å¸§å·®
    final difference = _calculateFrameDifference(currentData);
    
    if (difference > changeThreshold) {
      _lastFrameData = currentData;
      return true;
    }
    
    return false;
  }
  
  double _calculateFrameDifference(Uint8List currentData) {
    if (_lastFrameData == null || _lastFrameData!.length != currentData.length) {
      return 1.0;
    }
    
    int diffSum = 0;
    int pixelCount = currentData.length ~/ 4;  // RGBA
    
    for (int i = 0; i < currentData.length; i += 4) {
      // åªæ¯”è¾ƒ RGBï¼Œå¿½ç•¥ Alpha
      int rDiff = (currentData[i] - _lastFrameData![i]).abs();
      int gDiff = (currentData[i + 1] - _lastFrameData![i + 1]).abs();
      int bDiff = (currentData[i + 2] - _lastFrameData![i + 2]).abs();
      diffSum += (rDiff + gDiff + bDiff) ~/ 3;
    }
    
    return diffSum / (pixelCount * 255);
  }
  
  void reset() {
    _lastFrameData = null;
  }
}
```

### 2.3 å‰ç«¯æƒ…ç»ªé‡‡é›†ä¿®æ”¹

#### 2.3.1 ä¿®æ”¹ `interview_live_page.dart`

```dart
// æ–°å¢çŠ¶æ€å˜é‡ (çº¦ç¬¬ 30-45 è¡Œé™„è¿‘)
class _InterviewLivePageState extends State<InterviewLivePage> {
  // ... ç°æœ‰å˜é‡ ...
  
  // ğŸ†• æƒ…ç»ªæ•°æ®ç´¯ç§¯åˆ—è¡¨
  final List<EmotionRecord> _emotionRecords = [];
  
  // ğŸ†• æ™ºèƒ½é‡‡æ ·æœåŠ¡
  EmotionSamplingService? _samplingService;
  
  // ğŸ†• é™é‡‡æ ·ç”»å¸ƒ (ç”¨äºå¸§å·®æ£€æµ‹)
  html.CanvasElement? _samplingCanvas;

// ä¿®æ”¹ _captureAndAnalyze() å‡½æ•° (çº¦ç¬¬ 349-375 è¡Œ)
Future<void> _captureAndAnalyze() async {
  if (_visionBusy || _videoEl == null || !_cameraReady || 
      !_isRecording || _isPaused || _interviewId == null) return;
  if (_videoEl!.videoWidth == 0 || _videoEl!.videoHeight == 0) return;

  // ğŸ†• æ™ºèƒ½é‡‡æ ·æ£€æµ‹ (Layer 1)
  _samplingCanvas ??= html.CanvasElement(width: 160, height: 120);
  _samplingCanvas!.context2D.drawImageScaled(
    _videoEl!, 0, 0, 160, 120
  );
  
  _samplingService ??= EmotionSamplingService();
  if (!_samplingService!.shouldAnalyze(_samplingCanvas!)) {
    // å˜åŒ–ä¸æ˜¾è‘—ï¼Œè·³è¿‡æœ¬æ¬¡åˆ†æ
    return;
  }

  _visionBusy = true;
  try {
    final bytes = await _frameBytes();
    final resp = await ApiService.analyzeVision(bytes, _interviewId!);
    
    // ğŸ†• è®¡ç®—ç›¸å¯¹æ—¶é—´æˆ³
    final timestampMs = _recordingStartedAt != null 
        ? DateTime.now().difference(_recordingStartedAt!).inMilliseconds
        : 0;
    
    setState(() {
      currentEmotion = resp['emotion'] ?? 'Unknown';
      stressLevel = (resp['stress_level'] ?? 0).toDouble();
      confidence = resp['confidence'] ?? 'medium';
      notes = resp['notes'] ?? '';
      _lastVisionAt = DateTime.now();
      _visionError = null;
      
      // ğŸ†• ç´¯ç§¯åˆ°åˆ—è¡¨
      _emotionRecords.add(EmotionRecord(
        timestampMs: timestampMs,
        emotion: currentEmotion,
        stressLevel: stressLevel,
        confidence: confidence,
        notes: notes,
      ));
      
      if (stressLevel > 7) {
        riskAlerts.add('âš ï¸ ${SimpleLocalizations.stressSpike} (${stressLevel.toStringAsFixed(1)})');
      }
    });
  } catch (e) {
    setState(() {
      _visionError = '$e';
    });
  } finally {
    _visionBusy = false;
  }
}

// ä¿®æ”¹ _stopRecording() å‡½æ•° (çº¦ç¬¬ 235-276 è¡Œ)
void _stopRecording() async {
  print('ğŸ›‘ [DEBUG] åœæ­¢å½•åˆ¶...');
  print('ğŸ›‘ [DEBUG] å½“å‰ interview_id: $_interviewId');
  
  setState(() {
    _isRecording = false;
    _isPaused = false;
  });
  _transcriptTimer?.cancel();
  _visionTimer?.cancel();
  _durationTimer?.cancel();
  
  // ğŸ¤ åœæ­¢éŸ³é¢‘é‡‡é›†...
  // ... ç°æœ‰ä»£ç  ...
  
  // ğŸ†• ä¸Šä¼ æƒ…ç»ªæ•°æ®
  if (_emotionRecords.isNotEmpty && _interviewId != null) {
    print('ğŸ“Š [Emotion] å‡†å¤‡ä¸Šä¼  ${_emotionRecords.length} æ¡æƒ…ç»ªè®°å½•...');
    try {
      await ApiService.saveEmotionEvents(
        _interviewId!,
        _emotionRecords.map((e) => e.toJson()).toList(),
      );
      print('âœ… [Emotion] æƒ…ç»ªæ•°æ®ä¸Šä¼ æˆåŠŸ');
    } catch (e) {
      print('âŒ [Emotion] ä¸Šä¼ å¤±è´¥: $e');
      // ä¸é˜»å¡è§†é¢‘ä¸Šä¼ 
    }
  }
  
  // ğŸ“¹ åœæ­¢å½•åˆ¶å¹¶ä¸Šä¼ æœ€ç»ˆæ–‡ä»¶
  await _stopVideoRecording();
  
  // ğŸ†• é‡ç½®é‡‡æ ·æœåŠ¡
  _samplingService?.reset();
  _emotionRecords.clear();
  
  print('ğŸ›‘ [DEBUG] å½•åˆ¶åœæ­¢å®Œæˆ');
}
```

### 2.4 å‰ç«¯ API æœåŠ¡æ‰©å±•

#### ä¿®æ”¹ `api_service.dart`

```dart
// æ–°å¢æ–¹æ³• (çº¦ç¬¬ 165 è¡Œå)

/// æ‰¹é‡ä¿å­˜æƒ…ç»ªåˆ†æäº‹ä»¶
static Future<Map<String, dynamic>> saveEmotionEvents(
  String interviewId,
  List<Map<String, dynamic>> events,
) async {
  final response = await http.post(
    Uri.parse('$baseUrl/analysis/emotion-events/batch'),
    headers: {'Content-Type': 'application/json'},
    body: json.encode({
      'interview_id': interviewId,
      'events': events,
    }),
  );

  if (response.statusCode == 200) {
    return json.decode(response.body);
  } else {
    throw Exception('Failed to save emotion events: ${response.statusCode} -> ${response.body}');
  }
}
```

### 2.5 åç«¯æ‰¹é‡ä¿å­˜ API

#### æ–°å¢æ¥å£ `analysis.py`

```python
# åœ¨ analysis.py ä¸­æ–°å¢ (çº¦ç¬¬ 105 è¡Œå)

from typing import List
from pydantic import BaseModel
from app.services.interview_event_service import record_interview_event, get_interview_org_id
from app.services.transcript_service import get_supabase
from fastapi import Depends
from supabase import Client

class EmotionEvent(BaseModel):
    timestamp_ms: int
    emotion: str
    stress_level: float
    confidence: str
    notes: str = ""

class EmotionEventBatch(BaseModel):
    interview_id: str
    events: List[EmotionEvent]

class BatchSaveResponse(BaseModel):
    status: str
    saved_count: int
    interview_id: str

@router.post("/emotion-events/batch", response_model=BatchSaveResponse)
async def save_emotion_events_batch(
    batch: EmotionEventBatch,
    supabase: Client = Depends(get_supabase)
):
    """
    æ‰¹é‡ä¿å­˜æƒ…ç»ªåˆ†æäº‹ä»¶åˆ°æ•°æ®åº“
    
    - **interview_id**: é¢è¯• ID
    - **events**: æƒ…ç»ªäº‹ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« timestamp_ms, emotion, stress_level ç­‰
    
    äº‹ä»¶å°†ä¿å­˜åˆ° aura_interview_events è¡¨ï¼Œevent_type = 'emotion_analysis'
    """
    logger.info(f"ğŸ“Š [Emotion Batch] æ”¶åˆ°æ‰¹é‡ä¿å­˜è¯·æ±‚: interview_id={batch.interview_id}, count={len(batch.events)}")
    
    try:
        # éªŒè¯é¢è¯• ID å¹¶è·å– org_id
        org_id = get_interview_org_id(supabase, batch.interview_id)
        
        saved_count = 0
        for event in batch.events:
            try:
                record_interview_event(
                    supabase,
                    batch.interview_id,
                    "emotion_analysis",  # event_type
                    {
                        "emotion": event.emotion,
                        "stress_level": event.stress_level,
                        "confidence": event.confidence,
                        "notes": event.notes,
                        "timestamp_ms": event.timestamp_ms,  # ç›¸å¯¹æ—¶é—´æˆ³
                    },
                    org_id=org_id,
                )
                saved_count += 1
            except Exception as e:
                logger.warning(f"ğŸ“Š [Emotion Batch] ä¿å­˜å•æ¡äº‹ä»¶å¤±è´¥: {e}")
                continue
        
        logger.info(f"ğŸ“Š [Emotion Batch] âœ… ä¿å­˜å®Œæˆ: {saved_count}/{len(batch.events)} æ¡")
        
        return BatchSaveResponse(
            status="success",
            saved_count=saved_count,
            interview_id=batch.interview_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ“Š [Emotion Batch] âŒ æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to save emotion events: {str(e)}")
```

---

## 3. æŠ¥å‘Šé¡µé¢å¢å¼º

### 3.1 æƒ…ç»ªæ—¶é—´çº¿äº¤äº’

#### ä¿®æ”¹ `_buildEmotionTimeline()` æ–¹æ³•

```dart
// interview_report_page.dart çº¦ç¬¬ 380-452 è¡Œ

Widget _buildEmotionTimeline() {
  final emotionEvents = _events.where((e) => 
    e['event_type'] == 'emotion_analysis'
  ).toList();
  
  // ğŸ†• æŒ‰æ—¶é—´æˆ³æ’åº
  emotionEvents.sort((a, b) {
    final aTs = a['payload']?['timestamp_ms'] ?? a['timestamp_ms'] ?? 0;
    final bTs = b['payload']?['timestamp_ms'] ?? b['timestamp_ms'] ?? 0;
    return aTs.compareTo(bTs);
  });

  return Card(
    color: const Color(0xFF1F2937),
    child: Padding(
      padding: const EdgeInsets.all(24),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          Row(
            mainAxisAlignment: MainAxisAlignment.spaceBetween,
            children: [
              Text(
                SimpleLocalizations.emotionTimeline,
                style: TextStyle(
                  color: Colors.grey[500],
                  fontSize: 12,
                  letterSpacing: 1,
                ),
              ),
              // ğŸ†• æ˜¾ç¤ºæ€»æ•°
              if (emotionEvents.isNotEmpty)
                Text(
                  '${emotionEvents.length} ä¸ªæ•°æ®ç‚¹',
                  style: TextStyle(color: Colors.grey[600], fontSize: 10),
                ),
            ],
          ),
          const SizedBox(height: 16),
          if (emotionEvents.isEmpty)
            _buildEmptyState()
          else
            SizedBox(
              height: 220,
              child: ListView.builder(
                scrollDirection: Axis.horizontal,
                itemCount: emotionEvents.length,
                itemBuilder: (context, index) {
                  final event = emotionEvents[index];
                  final payload = event['payload'] ?? event['event_data'] ?? {};
                  final timestampMs = payload['timestamp_ms'] ?? 0;
                  
                  return _buildEmotionCard(
                    index: index,
                    emotion: payload['emotion'] ?? 'Unknown',
                    stressLevel: (payload['stress_level'] ?? 0).toDouble(),
                    confidence: payload['confidence'] ?? 'medium',
                    timestampMs: timestampMs,
                    onTap: () => _seekToTimestamp(timestampMs),
                  );
                },
              ),
            ),
        ],
      ),
    ),
  );
}

Widget _buildEmptyState() {
  return Container(
    height: 120,
    alignment: Alignment.center,
    child: Column(
      mainAxisAlignment: MainAxisAlignment.center,
      children: [
        Icon(Icons.timeline, size: 40, color: Colors.grey[700]),
        const SizedBox(height: 8),
        Text(
          SimpleLocalizations.noEmotionData,
          style: const TextStyle(color: Colors.grey),
        ),
      ],
    ),
  );
}

Widget _buildEmotionCard({
  required int index,
  required String emotion,
  required double stressLevel,
  required String confidence,
  required int timestampMs,
  required VoidCallback onTap,
}) {
  // ğŸ†• æƒ…ç»ªå¯¹åº”çš„é¢œè‰²
  final emotionColors = {
    'happy': Colors.green,
    'sad': Colors.blue,
    'angry': Colors.red,
    'surprised': Colors.orange,
    'fear': Colors.purple,
    'neutral': Colors.grey,
  };
  
  final color = emotionColors[emotion.toLowerCase()] ?? Colors.grey;
  
  return GestureDetector(
    onTap: onTap,  // ğŸ†• ç‚¹å‡»è·³è½¬è§†é¢‘
    child: Container(
      width: 130,
      margin: const EdgeInsets.only(right: 12),
      padding: const EdgeInsets.all(12),
      decoration: BoxDecoration(
        color: const Color(0xFF111827),
        borderRadius: BorderRadius.circular(8),
        border: Border.all(color: color.withOpacity(0.3)),
      ),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          // æ—¶é—´æˆ³ (å¯ç‚¹å‡»æç¤º)
          Row(
            children: [
              Icon(Icons.play_circle_outline, size: 14, color: Colors.blue[300]),
              const SizedBox(width: 4),
              Text(
                _formatTimestamp(timestampMs),
                style: TextStyle(
                  color: Colors.blue[300],
                  fontSize: 11,
                  fontWeight: FontWeight.w500,
                ),
              ),
            ],
          ),
          const SizedBox(height: 8),
          // æƒ…ç»ªæ ‡ç­¾
          Container(
            padding: const EdgeInsets.symmetric(horizontal: 8, vertical: 4),
            decoration: BoxDecoration(
              color: color.withOpacity(0.2),
              borderRadius: BorderRadius.circular(4),
            ),
            child: Text(
              emotion,
              style: TextStyle(
                color: color,
                fontWeight: FontWeight.bold,
                fontSize: 12,
              ),
            ),
          ),
          const SizedBox(height: 12),
          // å‹åŠ›ç­‰çº§
          Text(
            '${SimpleLocalizations.stress}: ${stressLevel.toStringAsFixed(1)}',
            style: const TextStyle(color: Colors.grey, fontSize: 11),
          ),
          const SizedBox(height: 4),
          // å‹åŠ›æ¡
          LinearProgressIndicator(
            value: (stressLevel / 10).clamp(0.0, 1.0),
            backgroundColor: Colors.white12,
            valueColor: AlwaysStoppedAnimation<Color>(
              stressLevel > 7 ? Colors.red : 
              stressLevel > 4 ? Colors.orange : Colors.green,
            ),
          ),
          const SizedBox(height: 8),
          // ç½®ä¿¡åº¦
          Text(
            confidence,
            style: TextStyle(color: Colors.grey[600], fontSize: 10),
          ),
        ],
      ),
    ),
  );
}

String _formatTimestamp(int ms) {
  final seconds = ms ~/ 1000;
  final minutes = seconds ~/ 60;
  final remainingSeconds = seconds % 60;
  return '${minutes.toString().padLeft(2, '0')}:${remainingSeconds.toString().padLeft(2, '0')}';
}
```

### 3.2 è§†é¢‘æ—¶é—´è·³è½¬åŠŸèƒ½

```dart
// interview_report_page.dart æ–°å¢

// ğŸ†• çŠ¶æ€å˜é‡
html.VideoElement? _videoElement;
String? _videoViewId;

// ğŸ†• è§†é¢‘è·³è½¬æ–¹æ³•
void _seekToTimestamp(int timestampMs) {
  if (_videoElement == null) {
    ScaffoldMessenger.of(context).showSnackBar(
      const SnackBar(
        content: Text('è¯·å…ˆåŠ è½½è§†é¢‘'),
        backgroundColor: Colors.orange,
      ),
    );
    return;
  }
  
  final seconds = timestampMs / 1000.0;
  print('ğŸ¬ [Video] è·³è½¬åˆ°æ—¶é—´ç‚¹: ${_formatTimestamp(timestampMs)} ($seconds ç§’)');
  
  _videoElement!.currentTime = seconds;
  _videoElement!.play();
  
  // æ˜¾ç¤ºæç¤º
  ScaffoldMessenger.of(context).showSnackBar(
    SnackBar(
      content: Text('è·³è½¬åˆ° ${_formatTimestamp(timestampMs)}'),
      duration: const Duration(seconds: 1),
      backgroundColor: Colors.blue,
    ),
  );
}

// ğŸ†• ä¿®æ”¹ _buildVideoSection() ä»¥ä¿å­˜è§†é¢‘å…ƒç´ å¼•ç”¨
Widget _buildVideoSection() {
  final videoUrl = _interviewData?['recording_url'];
  
  if (videoUrl == null) {
    return _buildNoVideoPlaceholder();
  }
  
  // åˆ›å»ºå¹¶æ³¨å†Œè§†é¢‘å…ƒç´ 
  if (_videoViewId == null) {
    final video = html.VideoElement()
      ..src = videoUrl
      ..controls = true
      ..style.width = '100%'
      ..style.height = '100%'
      ..style.borderRadius = '8px';
    
    _videoElement = video;
    _videoViewId = 'report-video-${DateTime.now().millisecondsSinceEpoch}';
    ui_web.platformViewRegistry.registerViewFactory(_videoViewId!, (_) => video);
  }

  return Card(
    color: const Color(0xFF1F2937),
    child: Padding(
      padding: const EdgeInsets.all(24),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          Row(
            mainAxisAlignment: MainAxisAlignment.spaceBetween,
            children: [
              Text(
                SimpleLocalizations.videoRecording,
                style: TextStyle(
                  color: Colors.grey[500],
                  fontSize: 12,
                  letterSpacing: 1,
                ),
              ),
              // ğŸ†• æç¤ºå¯ç‚¹å‡»æ—¶é—´çº¿
              Text(
                'ç‚¹å‡»æƒ…ç»ªæ—¶é—´çº¿å¯è·³è½¬',
                style: TextStyle(color: Colors.blue[300], fontSize: 10),
              ),
            ],
          ),
          const SizedBox(height: 16),
          Container(
            height: 280,
            decoration: BoxDecoration(
              color: const Color(0xFF111827),
              borderRadius: BorderRadius.circular(8),
            ),
            child: ClipRRect(
              borderRadius: BorderRadius.circular(8),
              child: HtmlElementView(viewType: _videoViewId!),
            ),
          ),
        ],
      ),
    ),
  );
}

Widget _buildNoVideoPlaceholder() {
  return Card(
    color: const Color(0xFF1F2937),
    child: Padding(
      padding: const EdgeInsets.all(24),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          Text(
            SimpleLocalizations.videoRecording,
            style: TextStyle(
              color: Colors.grey[500],
              fontSize: 12,
              letterSpacing: 1,
            ),
          ),
          const SizedBox(height: 16),
          Container(
            height: 200,
            alignment: Alignment.center,
            decoration: BoxDecoration(
              color: const Color(0xFF111827),
              borderRadius: BorderRadius.circular(8),
            ),
            child: Column(
              mainAxisAlignment: MainAxisAlignment.center,
              children: [
                const Icon(Icons.video_library_outlined, size: 48, color: Colors.grey),
                const SizedBox(height: 12),
                Text(SimpleLocalizations.noVideo, style: const TextStyle(color: Colors.grey)),
              ],
            ),
          ),
        ],
      ),
    ),
  );
}
```

---

## 4. æ•°æ®åº“è®¾è®¡

### 4.1 ä½¿ç”¨ç°æœ‰è¡¨ç»“æ„

å¤ç”¨ `aura_interview_events` è¡¨ï¼Œæ— éœ€æ–°å»ºè¡¨ï¼š

```sql
-- å·²å­˜åœ¨çš„è¡¨ç»“æ„ (aura_schema_v2_saas.sql)
CREATE TABLE aura_interview_events (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    interview_id UUID REFERENCES aura_interviews(id) NOT NULL,
    org_id UUID REFERENCES aura_organizations(id) NOT NULL,
    timestamp_ms INTEGER NOT NULL,  -- è·ç¦»é¢è¯•å¼€å§‹çš„æ¯«ç§’æ•°
    event_type TEXT NOT NULL,       -- 'emotion_analysis'
    payload JSONB NOT NULL,         -- æƒ…ç»ªæ•°æ® JSON
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### 4.2 æƒ…ç»ªäº‹ä»¶ Payload ç»“æ„

```json
{
  "event_type": "emotion_analysis",
  "timestamp_ms": 45000,
  "payload": {
    "emotion": "surprised",
    "stress_level": 6.5,
    "confidence": "high",
    "notes": "å€™é€‰äººåœ¨å›ç­”ç¦»èŒåŸå› æ—¶è¡¨ç°å‡ºæƒŠè®¶",
    "timestamp_ms": 45000
  }
}
```

### 4.3 æŸ¥è¯¢ç¤ºä¾‹

```sql
-- è·å–æŸæ¬¡é¢è¯•çš„æ‰€æœ‰æƒ…ç»ªäº‹ä»¶
SELECT 
    timestamp_ms,
    payload->>'emotion' as emotion,
    (payload->>'stress_level')::float as stress_level,
    payload->>'confidence' as confidence,
    created_at
FROM aura_interview_events
WHERE interview_id = 'xxx-xxx-xxx'
  AND event_type = 'emotion_analysis'
ORDER BY timestamp_ms ASC;
```

---

## 5. å®æ–½è®¡åˆ’

### é˜¶æ®µ 1: åŸºç¡€åŠŸèƒ½ (3-4 å°æ—¶)

| ä»»åŠ¡ | æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ |
|------|------|----------|
| 1.1 | `frontend/lib/models/emotion_record.dart` | æ–°å»º EmotionRecord æ¨¡å‹ |
| 1.2 | `frontend/lib/pages/interview_live_page.dart` | æ·»åŠ æœ¬åœ°ç´¯ç§¯åˆ—è¡¨å’Œä¿å­˜é€»è¾‘ |
| 1.3 | `frontend/lib/services/api_service.dart` | æ·»åŠ  `saveEmotionEvents` æ–¹æ³• |
| 1.4 | `backend/app/api/endpoints/analysis.py` | æ·»åŠ  `/emotion-events/batch` æ¥å£ |

**éªŒè¯ç‚¹**:
- [ ] å½•åˆ¶è¿‡ç¨‹ä¸­ `_emotionRecords` åˆ—è¡¨æ­£ç¡®ç´¯ç§¯
- [ ] åœæ­¢å½•åˆ¶æ—¶æˆåŠŸè°ƒç”¨æ‰¹é‡ä¿å­˜ API
- [ ] æ•°æ®åº“ä¸­èƒ½æŸ¥åˆ° `emotion_analysis` ç±»å‹äº‹ä»¶

### é˜¶æ®µ 2: æ™ºèƒ½é‡‡æ ·é›†æˆ (4-6 å°æ—¶)

| ä»»åŠ¡ | æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ |
|------|------|----------|
| 2.1 | `frontend/lib/services/emotion_sampling_service.dart` | æ–°å»ºæ™ºèƒ½é‡‡æ ·æœåŠ¡ |
| 2.2 | `frontend/lib/pages/interview_live_page.dart` | é›†æˆé‡‡æ ·æœåŠ¡åˆ° `_captureAndAnalyze` |
| 2.3 | è°ƒå‚ä¼˜åŒ– | è°ƒæ•´ `changeThreshold` å‚æ•° |

**éªŒè¯ç‚¹**:
- [ ] é™æ­¢ç”»é¢ä¸è§¦å‘åˆ†æï¼ˆèŠ‚çœ API è°ƒç”¨ï¼‰
- [ ] è¡¨æƒ…å˜åŒ–æ—¶æ­£å¸¸è§¦å‘åˆ†æ
- [ ] é‡‡æ ·ç‡é™ä½åˆ°åŸæ¥çš„ 20-30%

### é˜¶æ®µ 3: æŠ¥å‘Šé¡µé¢å¢å¼º (2-3 å°æ—¶)

| ä»»åŠ¡ | æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ |
|------|------|----------|
| 3.1 | `frontend/lib/pages/interview_report_page.dart` | ä¼˜åŒ– `_buildEmotionTimeline` UI |
| 3.2 | `frontend/lib/pages/interview_report_page.dart` | æ·»åŠ  `_seekToTimestamp` æ–¹æ³• |
| 3.3 | `frontend/lib/pages/interview_report_page.dart` | ä¿®æ”¹ `_buildVideoSection` ä¿å­˜è§†é¢‘å¼•ç”¨ |

**éªŒè¯ç‚¹**:
- [ ] æƒ…ç»ªæ—¶é—´çº¿æ­£ç¡®æ˜¾ç¤ºæ•°æ®
- [ ] ç‚¹å‡»æ—¶é—´çº¿å¡ç‰‡è§†é¢‘è·³è½¬åˆ°å¯¹åº”ä½ç½®
- [ ] æ—¶é—´æˆ³æ ¼å¼æ­£ç¡® (MM:SS)

---

## 6. æˆæœ¬ä¼˜åŒ–é¢„ä¼°

åŸºäº [è§†é¢‘åˆ†ææˆæœ¬ä¼˜åŒ–ç®—æ³•æ–¹æ¡ˆ](./20251121hw_è§†é¢‘åˆ†ææˆæœ¬ä¼˜åŒ–ç®—æ³•æ–¹æ¡ˆ.md) çš„è®¡ç®—ï¼š

| åœºæ™¯ | åŸå§‹æ–¹æ¡ˆ | ä¼˜åŒ–å | èŠ‚çœæ¯”ä¾‹ |
|------|----------|--------|----------|
| **é‡‡æ ·é¢‘ç‡** | æ¯ 3 ç§’ 1 å¸§ | ä»…å˜åŒ–æ—¶é‡‡æ · | -70% |
| **1 å°æ—¶é¢è¯•å¸§æ•°** | 1200 å¸§ | 300-400 å¸§ | -67% |
| **Gemini API æˆæœ¬** | $0.15/é¢è¯• | $0.04-0.05/é¢è¯• | -70% |
| **æœˆåº¦æˆæœ¬ (100åœº/å¤©)** | $450 | $120-150 | -70% |

---

## 7. æµ‹è¯•æ¸…å•

### 7.1 åŠŸèƒ½æµ‹è¯•

- [ ] **å½•åˆ¶é˜¶æ®µ**
  - [ ] æƒ…ç»ªæ•°æ®æ­£ç¡®ç´¯ç§¯åˆ°æœ¬åœ°åˆ—è¡¨
  - [ ] æ—¶é—´æˆ³è®¡ç®—æ­£ç¡®ï¼ˆç›¸å¯¹å½•åˆ¶å¼€å§‹æ—¶é—´ï¼‰
  - [ ] æ™ºèƒ½é‡‡æ ·è¿‡æ»¤é™æ­¢ç”»é¢

- [ ] **åœæ­¢å½•åˆ¶**
  - [ ] æƒ…ç»ªæ•°æ®æ‰¹é‡ä¸Šä¼ æˆåŠŸ
  - [ ] ä¸Šä¼ å¤±è´¥ä¸é˜»å¡è§†é¢‘ä¸Šä¼ 
  - [ ] åˆ—è¡¨æ­£ç¡®æ¸…ç©º

- [ ] **æŠ¥å‘Šé¡µé¢**
  - [ ] æƒ…ç»ªæ—¶é—´çº¿æ­£ç¡®åŠ è½½æ•°æ®
  - [ ] æ—¶é—´çº¿å¡ç‰‡æŒ‰æ—¶é—´æ’åº
  - [ ] ç‚¹å‡»è·³è½¬è§†é¢‘åŠŸèƒ½æ­£å¸¸

### 7.2 è¾¹ç•Œæµ‹è¯•

- [ ] æ— æƒ…ç»ªæ•°æ®æ—¶æ˜¾ç¤ºç©ºçŠ¶æ€
- [ ] ç½‘ç»œå¼‚å¸¸æ—¶çš„é”™è¯¯å¤„ç†
- [ ] è¶…é•¿é¢è¯•ï¼ˆ1å°æ—¶+ï¼‰æ•°æ®é‡å¤„ç†

---

## 8. ç›¸å…³æ–‡æ¡£

- [è§†é¢‘åˆ†ææˆæœ¬ä¼˜åŒ–ç®—æ³•æ–¹æ¡ˆ](./20251121hw_è§†é¢‘åˆ†ææˆæœ¬ä¼˜åŒ–ç®—æ³•æ–¹æ¡ˆ.md) - å››å±‚æ¼æ–—ç­–ç•¥è¯¦è§£
- [æ™ºèƒ½æ‹›è˜ç³»ç»Ÿæ¶æ„è®¾è®¡æ–‡æ¡£](../é¡¹ç›®éœ€æ±‚/æ‹›è˜æ™ºèƒ½ä½“/20251121hw_æ™ºèƒ½æ‹›è˜ç³»ç»Ÿæ¶æ„è®¾è®¡æ–‡æ¡£.md)
- [API è®¾è®¡æ–‡æ¡£](../åå°api/20251121hw_API_è®¾è®¡æ–‡æ¡£.md)

---

**æ–‡æ¡£ç‰ˆæœ¬å†å²**:

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | ä¿®æ”¹å†…å®¹ |
|------|------|------|----------|
| v1.0 | 2025-11-26 | AI Assistant | åˆå§‹ç‰ˆæœ¬ï¼Œæ•´åˆæƒ…ç»ªä¿å­˜ä¸æˆæœ¬ä¼˜åŒ–æ–¹æ¡ˆ |

